{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize hand-written digits with Machine Learning\n",
    "\n",
    "In this tutorial I'm going to demonstrate how to build up a classifier for hand-written digits using the algorithm of Random Forest, how to validate the model and how to tune the model for better performance.\n",
    "\n",
    "To run this ipython notebook you'll need to install Anaconda which is an open data science platform powered by Python and can be found from the link below:\n",
    "https://www.continuum.io/downloads\n",
    "\n",
    "The MNIST sample data can be dowloaded from Kaggle, the largest data science community in the world, where you can also find numerous of tutorials, starter scripts, instructions and much more.\n",
    "\n",
    "https://www.kaggle.com/c/digit-recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Dataframe\n",
    "from sklearn.ensemble import RandomForestClassifier # Classification algorithm - random forest\n",
    "from sklearn import metrics, grid_search\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import math\n",
    "import random as rd\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = pd.read_csv('train.csv')\n",
    "print (\"Loading finished.\")\n",
    "print (\"Data size:\", mnist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "\n",
    "* The dataset (train.csv) contains 42,000 rows.\n",
    "* Each row contains 785 integers.\n",
    "    * The first integer is called label, standing for the actual number the image is.\n",
    "    * Pixel0-pixel783 are grayscales of a 28*28 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the digits\n",
    "\n",
    "Here we are using matplotlib to plot the digits stored in pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = [ img.reshape(28, 28) for img in mnist.drop('label',axis=1).values]\n",
    "images = np.array(images)\n",
    "labels = mnist.label.values\n",
    "\n",
    "plt.figure(figsize=(10,10), dpi=600)\n",
    "for i in range(64):\n",
    "    plt.subplot(8,8,(i+1))\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=1, wspace=None, hspace=None)\n",
    "    plt.title(\"Label: %d\" % (labels[i]))\n",
    "    plt.axis(\"off\")\n",
    "    pl.imshow(images[i],cmap=pl.cm.gray_r)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's take a closer look at the 12th digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 11\n",
    "plt.figure(figsize=(5,5), dpi=28*28)\n",
    "plt.title(\"Label: %d\" % (labels[i]))\n",
    "plt.imshow(images[i],cmap=pl.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split\n",
    "We'll split the data into two parts: training and test.\n",
    "* Training data will be used to \"train\" the machine to learn how to recognize the digits - 32,000 records.\n",
    "* Test data will be used to validate the accuracy of the model - 10,000 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = mnist.drop('label',axis=1)[:32000].values\n",
    "train_y = mnist.label[:32000]\n",
    "test_x = mnist.drop('label',axis=1)[32000:].values\n",
    "test_y = mnist.label[32000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building\n",
    "\n",
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(predictions, test_y))\n",
    "print(\"Accuracy score: %f\" % metrics.accuracy_score(predictions, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize incorrectly predicted digits\n",
    "\n",
    "The first digit on top of each image is the actual number and the second one is what's predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incorrect_images = []\n",
    "incorrect_labels = []\n",
    "incorrect_predictions = []\n",
    "incorrect_data = []\n",
    "\n",
    "actual_label = 7\n",
    "pred_label = 9\n",
    "\n",
    "for (image, label, prediction) in zip(test_x, test_y, predictions):\n",
    "    if label==actual_label and prediction==pred_label:\n",
    "        incorrect_data.append(image)\n",
    "        incorrect_images.append(image.reshape(28,28))\n",
    "        incorrect_labels.append(label)\n",
    "        incorrect_predictions.append(prediction)\n",
    "\n",
    "incorrect_images = np.array(incorrect_images)\n",
    "\n",
    "plt.figure(figsize=(20,10), dpi=600)\n",
    "for i in range(min([len(incorrect_images),10])):\n",
    "    plt.subplot(1,min([len(incorrect_images),10]),(i+1))\n",
    "    plt.title(\"%d : %d\" % (incorrect_labels[i], incorrect_predictions[i]))\n",
    "    pl.imshow(incorrect_images[i],cmap=pl.cm.gray_r)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune the model\n",
    "One algorithm may have many parameters and untuned parameters may impact the results significantly. Paramter tuning is one of the biggest challenges in practical machine learning. There are typically two approaches for tuning:\n",
    "* Automated tuning. For instance, grid search and bayersian optimazition\n",
    "    * Requires less relatively less knowlege and experience.\n",
    "    * Time consuming.\n",
    "* Manual tuning\n",
    "    * More knowlege and experience required.\n",
    "    * Time efficient.\n",
    "    \n",
    "    \n",
    "Here we'll use grid search for automated parameters tuning. What grid search does is to firstly create a space of parameter combinations then train/validate the model for each combinations and finally pick up the best-performed one.\n",
    "\n",
    "There are three parameters we will be tuning for Random Forest:\n",
    "\n",
    "* n_estimators - The number of trees in the \"forest\". Generally the larger it is, the better the performance will be.\n",
    "* criterion - The function to measure the quality of a branch split of decision trees.\n",
    "* max_depth - The maximum depth of the tree. Larger number indicates more complexities and greater chance of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search_model(train_x, train_y, est, param_grid, n_jobs, cv):\n",
    "    model = grid_search.GridSearchCV(estimator  = est,\n",
    "                                     param_grid = param_grid,\n",
    "#                                      scoring    = 'roc_auc',\n",
    "                                     verbose    = 10,\n",
    "                                     n_jobs  = n_jobs,\n",
    "                                     iid        = True,\n",
    "                                     refit    = True,\n",
    "                                     cv      = cv)\n",
    "    # Fit Grid Search Model\n",
    "    model.fit(train_x, train_y)\n",
    "    print(\"Best score: %0.3f\" % model.best_score_)\n",
    "    print(\"Best parameters set:\", model.best_params_)\n",
    "    return model\n",
    "\n",
    "param_grid = {'n_estimators': [10,50,100]\n",
    "                , 'criterion': ['gini','entropy']\n",
    "                , 'max_depth': [10,20,30]\n",
    "              }\n",
    "model = search_model(train_x\n",
    "                                         , train_y\n",
    "                                         , RandomForestClassifier()\n",
    "                                         , param_grid\n",
    "                                         , n_jobs=1\n",
    "                                         , cv=3)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Validate the tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuned_predictions = model.predict(test_x)\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(tuned_predictions, test_y))\n",
    "print(\"Accuracy score of tuned model: %f\" % metrics.accuracy_score(tuned_predictions, test_y))\n",
    "print(\"Accuracy score of default model: %f\" % metrics.accuracy_score(tuned_predictions, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's improved?\n",
    "\n",
    "We'll make predictions for those digits that were incorrectly predicted by the untuned model, with the tuned model, then plot them to see what's improved and what's not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuned_val_predictions = model.predict(incorrect_data)\n",
    "plt.figure(figsize=(20,10), dpi=600)\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,(i+1))\n",
    "    plt.title(\"Before: %d, after: %d\" % (incorrect_predictions[i],tuned_val_predictions[i]))\n",
    "    pl.imshow(incorrect_images[i],cmap=pl.cm.gray_r)\n",
    "pl.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
